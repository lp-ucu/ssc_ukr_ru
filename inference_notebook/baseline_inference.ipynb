{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial steps"
      ],
      "metadata": {
        "id": "tDA9WmEQOBxg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0gCCPofZA8VN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee7865d-2eb1-47dd-a975-8baa5fa5c300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# needed for wav2vec models\n",
        "# no need to run it if wav2vec with lm models are not selected (deafault)\n",
        "!pip install kenlm pyctcdecode > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R0SIfXnowlNS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ASR supported models**:\n",
        "```\n",
        "          \"openai/whisper-tiny\",\n",
        "          \"openai/whisper-base\",\n",
        "          \"openai/whisper-small\", # ----> 244M\n",
        "          \"openai/whisper-medium\", # ---> 769M\n",
        "          \"openai/whisper-large\", # ---> 1550M\n",
        "          \"openai/whisper-large-v2\",\n",
        "          \"openai/whisper-large-v3\",\n",
        "```\n",
        "finetuned on Ukrainian:\n",
        "```\n",
        "          \"Yehor/wav2vec2-xls-r-300m-uk-with-small-lm\" # ---> with kenlm and pyctcdecode\n",
        "          \"arampacha/whisper-large-uk-2\",\n",
        "          \"robinhad/wav2vec2-xls-r-300m-uk\", # ---> no lm\n",
        "          \"Yehor/w2v-bert-2.0-uk\", # ---> 600M\n",
        "          \"Yehor/wav2vec2-xls-r-1b-uk-with-lm\",\n",
        "          \"arampacha/wav2vec2-xls-r-1b-uk\",\n",
        "          \"voidful/wav2vec2-xlsr-multilingual-56\",\n",
        "          \"facebook/wav2vec2-base-960h\" ---> only english\n",
        "```\n",
        "\n",
        "\n",
        "**Supported classification models**:\n",
        "\n",
        "zero-shot classification (multilingual):\n",
        "```\n",
        "          \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\",\n",
        "          \"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\",\n",
        "          \"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"\n",
        "```\n",
        "tuned for sentiment classification (english):\n",
        "```\n",
        "          \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
        "          \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "          \"siebert/sentiment-roberta-large-english\",\n",
        "\n",
        "```\n",
        "\n",
        "tuned for emotion recognition\n",
        "```\n",
        "          \"SamLowe/roberta-base-go_emotions\"\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**Supported LLMs**:\n",
        "```\n",
        "          \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "```"
      ],
      "metadata": {
        "id": "QG250g0BtMUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best results was obtained using `openai/whisper-large-v2` in translation mode (to English) following the pre-trained sentiment classifier `cardiffnlp/twitter-roberta-base-sentiment-latest`: accuracy 84%"
      ],
      "metadata": {
        "id": "-Goo7i3yu-zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BEST PARAMETERS:\n",
        "\n",
        "asr_model_name = 'openai/whisper-large-v2'\n",
        "\n",
        "# set False to transcribe to original language\n",
        "# note, translate=True works with Whisper model only\n",
        "translate = True\n",
        "\n",
        "classification_model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest' #by default this model classifies to 'positive', 'negative' and 'neutral' sentiment\n",
        "# labels need to be set manually for zero-shot-classification models\n",
        "labels = None\n",
        "# need to specify which labels we considered to be negative\n",
        "negative_labels = [\"negative\"]\n",
        "\n",
        "# disable llm\n",
        "llm_model_name = ''\n",
        "prompt = ''"
      ],
      "metadata": {
        "id": "JCg3bJkOcLdu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Whisper is cutting audio by 30 sec. Wav2Vec2 model use the whole audio file, therefore this model may use much more RAM"
      ],
      "metadata": {
        "id": "bGGLmKp2iAKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = 'file.wav'"
      ],
      "metadata": {
        "id": "FWZA1b7dOKwo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6K22wa9qCmhI"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display\n",
        "\n",
        "display(Audio(audio_file, autoplay=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models' interface"
      ],
      "metadata": {
        "id": "8TmWuGSK6Nc1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY3I05kHwDEk"
      },
      "source": [
        "## ASR models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS7K53y-D0DK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from transformers import AutoModelForCTC, Wav2Vec2BertProcessor\n",
        "from transformers import pipeline\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwAXraibD05M"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "print(device, torch_dtype)\n",
        "#TODO: W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQiUdsJtGuwF"
      },
      "outputs": [],
      "source": [
        "# utils\n",
        "def read_audio(fname):\n",
        "  sr = 16000\n",
        "  speech, _ = librosa.load(fname, sr=sr, mono=True)\n",
        "  return speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpy9V1sicVXy"
      },
      "outputs": [],
      "source": [
        "# \"openai/whisper-{tiny}\"\n",
        "class Wav2Vec2BERTHuggingFace:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.processor = None\n",
        "    self.model = None\n",
        "    #self.forced_decoder_ids = None\n",
        "\n",
        "  def init(self):\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    self.model = AutoModelForCTC.from_pretrained(self.name).to(device)\n",
        "    self.processor = Wav2Vec2BertProcessor.from_pretrained(self.name)\n",
        "\n",
        "  def process_audio(self, audio_fname, lang=None, task=\"transcribe\"):\n",
        "    #task = transcribe/translate\n",
        "    speech = read_audio(audio_fname)\n",
        "\n",
        "    if speech is None:\n",
        "      print(f'speech == None for {audio_fname}')\n",
        "      return \"\"\n",
        "\n",
        "    input_features = self.processor(speech, sampling_rate=16000).input_features\n",
        "    features = torch.tensor(input_features).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      logits = self.model(features).logits\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    predictions = self.processor.batch_decode(predicted_ids)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V51EhY67nYaj"
      },
      "outputs": [],
      "source": [
        "class ASRPipelineHuggingFace:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.pipe = None\n",
        "\n",
        "  def init(self):\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    self.pipe = pipeline(\n",
        "      \"automatic-speech-recognition\",\n",
        "      model=self.name,\n",
        "      device=device\n",
        "    )\n",
        "\n",
        "  def process_audio(self, audio_fname, lang=None, task=\"transcribe\", chunk_lenght=30, stride=None):\n",
        "    #task = transcribe/translate\n",
        "    speech = read_audio(audio_fname)\n",
        "\n",
        "    if speech is None:\n",
        "      print(f'speech == None for {audio_fname}')\n",
        "      return \"\"\n",
        "\n",
        "    if stride is None:\n",
        "      stride = chunk_lenght / 6  # default value https://github.com/huggingface/transformers/blob/5cd16f01db3b5499d4665e8624801ed30ba87bdd/src/transformers/pipelines/automatic_speech_recognition.py\n",
        "\n",
        "    output = self.pipe(speech,\n",
        "                        return_timestamps=True,\n",
        "                        chunk_length_s=chunk_lenght,\n",
        "                        stride_length_s=stride,  #or set list [left, right]\n",
        "                        #batch_size=32,\n",
        "                        # note \"arampacha/whisper-large-uk-2\", does not support task parameter. need to pass it using old ways\n",
        "                        generate_kwargs={\"language\": lang, \"task\" : task}\n",
        "                       )\n",
        "\n",
        "    return output[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification models"
      ],
      "metadata": {
        "id": "mPQBe5UJr3cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "#generator = torch.Generator(device=device).manual_seed(42)"
      ],
      "metadata": {
        "id": "pyh9t0x6r64N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classifier(model_name=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"):\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if model_name in [\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\",\n",
        "                        \"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\",\n",
        "                        \"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"]:\n",
        "    classifier = pipeline(\"zero-shot-classification\", model=model_name, device=device)\n",
        "    return classifier\n",
        "\n",
        "  if model_name in [\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"]:\n",
        "    return pipeline(model=model_name, device=device)\n",
        "\n",
        "  if model_name in [\"siebert/sentiment-roberta-large-english\",\n",
        "                    \"cardiffnlp/twitter-roberta-base-sentiment-latest\"]:\n",
        "    return pipeline(\"sentiment-analysis\", model=model_name, device=device)\n",
        "\n",
        "  if model_name in [\"SamLowe/roberta-base-go_emotions\"]:\n",
        "    return pipeline(task=\"text-classification\", model=model_name, top_k=None)\n"
      ],
      "metadata": {
        "id": "KkHF19k-zKkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier_predict(text, classifier, labels):\n",
        "    if labels:\n",
        "      output = classifier(text, labels, max_length=512, truncation=True)\n",
        "      #predict = output['labels'][np.argmax(output['scores'])]\n",
        "    else:\n",
        "      output = classifier(text[:512]) # , generator=generator how to pass random seed???\n",
        "\n",
        "    if len(output) > 1:\n",
        "        output[0] = [x for x in output[0] if not ('neutral' == x.get('label'))]\n",
        "\n",
        "        predict = max(output[0], key=lambda x:x['score'])['label']\n",
        "    else:\n",
        "        predict = output[0]['label']\n",
        "\n",
        "    return predict"
      ],
      "metadata": {
        "id": "bKMPvX1hzR-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_to_binary(result, conflict_labels):\n",
        "  binary_res = 1 if result in conflict_labels else 0\n",
        "  return binary_res"
      ],
      "metadata": {
        "id": "n6yhw47zz_JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM models"
      ],
      "metadata": {
        "id": "GmD_j_CnzkJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "#device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = \"cpu\"\n",
        "\n",
        "def get_llm_model(llm_model_name):\n",
        "  if llm_model_name == \"mistralai/Mistral-7B-Instruct-v0.2\":\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "    return model, tokenizer\n",
        "  else:\n",
        "    print(f\"model {llm_model_name} is not supported\")\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "av47kzB1zj4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_llm(model, tokenizer, prompt_instruct, text):\n",
        "  prompt = f\"\"\"\n",
        "  {prompt_instruct}\n",
        "  Text: {text}\n",
        "  \"\"\"\n",
        "\n",
        "  messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "  ]\n",
        "\n",
        "  encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "\n",
        "  model_inputs = encodeds.to(device)\n",
        "  model.to(device)\n",
        "\n",
        "  generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "  decoded = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  return decoded[0]"
      ],
      "metadata": {
        "id": "7M5H36TrFLMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_binary_from_llm_output(text):\n",
        "  new_text = re.split('\\W+', text.split('[/INST]')[1])[1].strip()\n",
        "  return 1 if new_text.lower() == \"conflict\" else 0"
      ],
      "metadata": {
        "id": "iHRKFGISI3fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "sqiTiHd20ALJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "zhPaG3GO7sTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference (audio_file_path, asr_model_name, translate, classification_model_name, labels, negative_labels, llm_model_name='', prompt='', debug=True):\n",
        "  # === ASR model ===\n",
        "  if \"w2v\" in asr_model_name or \"wav2vec\" in asr_model_name:\n",
        "    asr_model = Wav2Vec2BERTHuggingFace(asr_model_name)\n",
        "  else:\n",
        "    asr_model = ASRPipelineHuggingFace(asr_model_name)\n",
        "\n",
        "  asr_model.init()\n",
        "\n",
        "  task = 'translate' if translate else 'transcribe'\n",
        "  asr_out = asr_model.process_audio(audio_file_path, task=task)\n",
        "  if debug:\n",
        "    print(f\"Output of ASR model ({task} task):\")\n",
        "    display(asr_out)\n",
        "  del asr_model\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # === classification model ===\n",
        "  if classification_model_name != '':\n",
        "    classification_model = get_classifier(classification_model_name)\n",
        "    class_label = classifier_predict(asr_out, classification_model, labels)\n",
        "    if debug:\n",
        "      print(f\"\\nclassification label: {class_label}\")\n",
        "    binary_label = output_to_binary(class_label, negative_labels)\n",
        "    del classification_model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  # === LLM model ===\n",
        "  elif llm_model_name != '':\n",
        "    llm_model, llm_tokenizer = get_llm_model(llm_model_name)\n",
        "    output = predict_llm(llm_model, llm_tokenizer, prompt, asr_out)\n",
        "    if debug:\n",
        "      print(output)\n",
        "    binary_label = get_binary_from_llm_output(output)\n",
        "    del llm_model, llm_tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "  else:\n",
        "    print(\"Classification model or LLM name is not defined\")\n",
        "    return None, None\n",
        "\n",
        "  if debug:\n",
        "    print(f\"\\nRESULT: {'conflict' if binary_label else 'no conflict present'}\\n\")\n",
        "\n",
        "  return asr_out, binary_label"
      ],
      "metadata": {
        "id": "oxV4GurR2Or0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference (best results)"
      ],
      "metadata": {
        "id": "93Kd48sw7v0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "_, _ = inference(audio_file, asr_model_name, translate, classification_model_name, labels, negative_labels, debug=True)"
      ],
      "metadata": {
        "id": "a9fG0REw3CVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 min on T4 GPU, 3 min on CPU"
      ],
      "metadata": {
        "id": "4THZZ_z2SMUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference (original language)"
      ],
      "metadata": {
        "id": "wRDHVs7k9wpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asr_model_name = 'openai/whisper-large-v2'\n",
        "translate = False\n",
        "classification_model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
        "labels = [\"позитив\",\"негатив\",\"нейтральне\"]\n",
        "negative_labels = [\"негатив\"]\n",
        "llm_model_name = ''\n",
        "prompt = ''"
      ],
      "metadata": {
        "id": "aBhRQa7O9lIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "_, _ = inference(audio_file, asr_model_name, translate, classification_model_name, labels, negative_labels, debug=True)"
      ],
      "metadata": {
        "id": "dQMiyfFc9qZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference (LLM)"
      ],
      "metadata": {
        "id": "qUI0rSXp9zET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM usage (English):\n",
        "# Note, for me works only on CPU with High-RAM (it needs ~30GB RAM or GPU)\n",
        "\n",
        "asr_model_name = 'openai/whisper-large-v2'\n",
        "translate = True\n",
        "classification_model_name = ''\n",
        "llm_model_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
        "prompt_instruction = \"Analyze the following text (transcribed from the call center conversation) and decide if there is a conflict or miscommunication in this text. Provide 1 word as an answer (conflict or neutral):\"\n",
        "labels = []\n",
        "negative_labels = []"
      ],
      "metadata": {
        "id": "8R98hZqFEynf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "_, _ = inference(audio_file, asr_model_name, translate, classification_model_name, labels, negative_labels, llm_model_name, prompt_instruction, debug=True)"
      ],
      "metadata": {
        "id": "OFQjBEYjHnjI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}